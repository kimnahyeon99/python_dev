{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title :  테스트 페이지\n",
      "H1 태그 :  안녕하세요!\n",
      "P 태그 :  이것은 예제 문장입니다.\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = \"\"\"\n",
    "<html>\n",
    "    <head><title>테스트 페이지</title></head>\n",
    "    <body>\n",
    "        <h1>안녕하세요!</h1>\n",
    "        <p class=\"content\">이것은 예제 문장입니다.</p>\n",
    "        <a href=\"https://example.com\">예제 링크</a>\n",
    "    </body>\n",
    "</html>\n",
    "\"\"\"\n",
    "# BeautifulSoup object 생성\n",
    "# html 문자열을 파싱을 해야 한다. => DOM tree 생성\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# 태그 선택자\n",
    "title = soup.title.text\n",
    "print('title : ',title)\n",
    "h1 = soup.h1.text\n",
    "print('H1 태그 : ', h1)\n",
    "p = soup.p.text\n",
    "print('P 태그 : ',p)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사과\n",
      "바나나\n",
      "포도\n"
     ]
    }
   ],
   "source": [
    "# 특정 태그로 찾기\n",
    "# find_all(tag) : 해당 모든 tag를 찾는다. => 리스트로 반환된다.\n",
    "# find(tag) : 찾은 요소 중 첫번째만 반환\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = \"\"\"\n",
    "<ul>\n",
    "    <li>사과</li>\n",
    "    <li>바나나</li>\n",
    "    <li>포도</li>\n",
    "</ul>\n",
    "\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "li_items = soup.find_all('li') # 모든 li태그를 찾아라\n",
    "\n",
    "for li_item in li_items:\n",
    "    print(li_item.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "이름 :  홍길동\n",
      "이름 :  홍길동\n",
      "나이 :  30세\n",
      "홍길동\n",
      "30세\n"
     ]
    }
   ],
   "source": [
    "# CSS selector 사용\n",
    "# select(css selector) : 모두 찾기\n",
    "# select_one(css selector) : 하나만 찾기\n",
    "\n",
    "html = \"\"\"\n",
    "<div class=\"info\">\n",
    "    <p class=\"name\">홍길동</p>\n",
    "    <p class=\"age\">30세</p>\n",
    "</div>\n",
    "\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "name1 = soup.select_one('.name').text\n",
    "print(type(name1))\n",
    "print('이름 : ', name1)\n",
    "name2 = soup.find('p', class_='name').text\n",
    "print('이름 : ', name2)\n",
    "\n",
    "age = soup.select_one('.age').text\n",
    "print('나이 : ', age)\n",
    "\n",
    "# p tag 전체 선택\n",
    "p_tag = soup.select('p') # 모든 p tag 선택\n",
    "print(p_tag[0].text)\n",
    "print(p_tag[1].text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://example.com/page1', 'https://example.com/page2']\n"
     ]
    }
   ],
   "source": [
    "# 4. 링크(a tag), 이미지 크롤링\n",
    "html = \"\"\"\n",
    "<a href=\"https://example.com/page1\">페이지 1</a>\n",
    "<a href=\"https://example.com/page2\">페이지 2</a>\n",
    "\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "links = [a['href']for a in soup.find_all('a')]\n",
    "print(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://example.com/image1.jpg', 'https://example.com/image2.jpg']\n"
     ]
    }
   ],
   "source": [
    "# 이미지의 위치 추출 => 다운로드\n",
    "html = \"\"\"\n",
    "<img src=\"https://example.com/image1.jpg\" alt=\"이미지 1\">\n",
    "<img src=\"https://example.com/image2.jpg\" alt=\"이미지 2\">\n",
    "\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html,'html.parser')\n",
    "\n",
    "images_src = [img['src'] for img in soup.find_all('img')] # list로 나와서 하나씩 꺼내야 한다.\n",
    "print(images_src)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['이름', '나이']\n",
      "['김철수', '25']\n",
      "['이영희', '30']\n"
     ]
    }
   ],
   "source": [
    "# 테이블 태그 처리\n",
    " \n",
    "html = \"\"\"\n",
    "<table>\n",
    "    <tr>\n",
    "        <th>이름</th><th>나이</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>김철수</td><td>25</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>이영희</td><td>30</td>\n",
    "    </tr>\n",
    "</table>\n",
    "\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# 행 추출 (tr로 행 추출)\n",
    "rows = soup.find_all('tr')\n",
    "# print(rows)\n",
    "for row in rows: # 한 행씩 가져다가 처리\n",
    "    cols = row.find_all(['th','td'])\n",
    "    print([col.text for col in cols])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 메소드 정리\n",
    "##### 1. find, find_all : 특정 태그로 찾기\n",
    "##### 2. select, select_one : CSS selector로 찾기\n",
    "\n",
    "- find(tag) : 첫번째로 일치하는 태그 오브젝트 반환\n",
    "- find_all(tag, class_, limit=) : 일치하는 모든 태그 오브젝트를 리스트로 반환\n",
    "- find_parent() : 첫번째 부모 태그 오브젝트 반환\n",
    "- find_parents() : 모든 부모 태그 오브젝트 반환\n",
    "- find_next_sibling() : 다음 형제 태그 오브젝트 반환\n",
    "- find_previous_sibling() : 이전 형제 태그 오브젝트 반환\n",
    "\n",
    "- select_one() : CSS selector 사용해서 특정 태그 오브젝트 반환\n",
    "- select() : CSS selector 사용해서 모든 태그\n",
    "\n",
    "- 속성 (Attribute)\n",
    "    - tag, text : 텍스트 추출\n",
    "    - tag['속성명'] : 해당 속성의 값을 추출\n",
    "    - tag['속성명'] = 값 : 값 변경\n",
    "\n",
    "- 태그 제어\n",
    "    - tag.decompose() : 태그 제거\n",
    "    - tag.extract() : 태그 제거 후 반환\n",
    "    - soup.new_tag() : soup 오브젝트에 새로운 태그를 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<body>\n",
      "<h1>안녕하세요!</h1>\n",
      "<p class=\"content\">이것은 예제 문장입니다.</p>\n",
      "</body>\n",
      "body\n",
      "html\n",
      "[document]\n"
     ]
    }
   ],
   "source": [
    "html = \"\"\"\n",
    "<html>\n",
    "    <head><title>테스트 페이지</title></head>\n",
    "    <body>\n",
    "        <h1>안녕하세요!</h1>\n",
    "        <p class=\"content\">이것은 예제 문장입니다.</p>\n",
    "    </body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# p 태그 먼저 찾는다\n",
    "p_tag = soup.find('p')\n",
    "parent_tag = p_tag.find_parent()\n",
    "print(parent_tag)\n",
    "\n",
    "all_parents = p_tag.find_parents()\n",
    "for parent in all_parents:\n",
    "    print(parent.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1>안녕하세요!</h1>\n"
     ]
    }
   ],
   "source": [
    "html = \"\"\"\n",
    "<html>\n",
    "    <head><title>테스트 페이지</title></head>\n",
    "    <body>\n",
    "        <h1>안녕하세요!</h1>\n",
    "        <p class=\"content\">이것은 예제 문장입니다.</p>\n",
    "    </body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# p 태그 먼저 찾는다\n",
    "p_tag = soup.find('p')\n",
    "\n",
    "# 다음 형제 태그 추출\n",
    "print(p_tag.find_previous_sibling())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이것은 예제 두 번째 문장입니다.\n",
      "이것은 예제 두 번째 문장입니다.\n"
     ]
    }
   ],
   "source": [
    "html = \"\"\"\n",
    "<html>\n",
    "    <head><title>테스트 페이지</title></head>\n",
    "    <body>\n",
    "        <h1>안녕하세요!</h1>\n",
    "        <p class=\"content1\">이것은 예제 첫 번째 문장입니다.</p>\n",
    "        <p class=\"content2\">이것은 예제 두 번째 문장입니다.</p>\n",
    "    </body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# p 태그 먼저 찾는다\n",
    "p_tag = soup.select_one('p.content2')\n",
    "print(p_tag.text)\n",
    "\n",
    "p_tag = soup.select('p')\n",
    "print(p_tag[1].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a href=\"/item/board_read.naver?code=068270&amp;nid=297906968&amp;st=&amp;sw=&amp;page=2\" onclick=\"return singleSubmitCheck();\" title=\"신규 유입전에 보세요\">신규 유입전에 보세요\n",
      "\t\t\t\t\t\n",
      "\t\t\t\t\n",
      "\t\t\t\t<span class=\"tah p9\" style=\"color:#639933\">[<b>1</b>]</span>\n",
      "<img height=\"10\" src=\"https://ssl.pstatic.net/imgstock/images5/new.gif\" width=\"10\"/></a>]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "url = 'https://finance.naver.com/item/board.naver?code=068270&page=2'\n",
    "\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36\"\n",
    "}\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "\n",
    "posts = soup.select('#content > div.section.inner_sub > table.type2 > tbody > tr:nth-child(5) > td.title > a')\n",
    "print(posts)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "firstenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
